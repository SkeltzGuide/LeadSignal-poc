{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606387a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict\n",
    "\n",
    "# Hashing\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Scraping\n",
    "def scrape_target_site(\n",
    "    site_name: str,\n",
    "    base_url: str,\n",
    ") -> List[Dict]:\n",
    "    headers = {\n",
    "        \"User-Agent\": f\"LeadSignalBot/0.1 (+{site_name})\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def timetohire_parser(soup: BeautifulSoup, base_url: str) -> List[Dict]:\n",
    "    vacancies = []\n",
    "    cards = soup.select(\"div.VacatureList__Wrapper__Mk_7J\")\n",
    "\n",
    "    for card in cards:\n",
    "        # Title\n",
    "        title_tag = card.select_one(\"h3.VacatureList__Title__u4746\")\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"No title\"\n",
    "\n",
    "        # URL\n",
    "        link_tag = card.select_one(\"a.VacatureList__LinkBtn__3_4n3\")\n",
    "        href = link_tag.get(\"href\") if link_tag else \"#\"\n",
    "        url = href if href.startswith(\"http\") else base_url.rstrip(\"/\") + href\n",
    "\n",
    "        # Description\n",
    "        desc_tag = card.select_one(\"div.VacatureList__Content__mfD1j p\")\n",
    "        description = desc_tag.get_text(strip=True) if desc_tag else \"\"\n",
    "\n",
    "        vacancies.append({\n",
    "            \"company\": \"TTH\",\n",
    "            \"source\": \"job_board\",\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"description\": description\n",
    "        })\n",
    "\n",
    "    return vacancies\n",
    "\n",
    "\n",
    "# Hashing\n",
    "\n",
    "def generate_job_hash(job: Dict) -> str:\n",
    "    \"\"\"Create a unique hash for a job entry.\"\"\"\n",
    "    data = f\"{job['company']}{job['source']}{job['title']}\"\n",
    "    return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e163b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"tth.nl\"\n",
    "url = \"https://www.werkenbijtimetohire.nl/\"\n",
    "\n",
    "soup = scrape_target_site(site, url)\n",
    "results = timetohire_parser(soup, site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d559fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "BASE_DIR = os.getcwd()  # Gets the working directory of the notebook\n",
    "DB_NAME = os.path.join(BASE_DIR, \"jobs.db\")\n",
    "\n",
    "def init_db():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS jobs (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            hash TEXT UNIQUE,\n",
    "            title TEXT,\n",
    "            url TEXT,\n",
    "            description TEXT,\n",
    "            company TEXT,\n",
    "            source TEXT,\n",
    "            first_seen TEXT,\n",
    "            last_seen TEXT,\n",
    "            is_active INTEGER\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def store_jobs(jobs: List[Dict]):\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    now = datetime.utcnow().isoformat()\n",
    "\n",
    "    seen_hashes = set()\n",
    "\n",
    "    for job in jobs:\n",
    "        job_hash = generate_job_hash(job)\n",
    "        seen_hashes.add(job_hash)\n",
    "\n",
    "        cursor.execute(\"SELECT id FROM jobs WHERE hash = ?\", (job_hash,))\n",
    "        exists = cursor.fetchone()\n",
    "\n",
    "        if exists:\n",
    "            cursor.execute(\"\"\"\n",
    "                UPDATE jobs SET last_seen = ?, is_active = 1 WHERE hash = ?\n",
    "            \"\"\", (now, job_hash))\n",
    "        else:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO jobs (\n",
    "                    hash, title, url, description,\n",
    "                    company, source,\n",
    "                    first_seen, last_seen, is_active\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, 1)\n",
    "            \"\"\", (\n",
    "                job_hash,\n",
    "                job['title'],\n",
    "                job['url'],\n",
    "                job['description'],\n",
    "                job.get('company', 'Unknown'),\n",
    "                job.get('source', 'Unknown'),\n",
    "                now,\n",
    "                now\n",
    "            ))\n",
    "\n",
    "    # Flag missing jobs as inactive\n",
    "    cursor.execute(\"SELECT hash FROM jobs WHERE is_active = 1\")\n",
    "    all_active = cursor.fetchall()\n",
    "    for (existing_hash,) in all_active:\n",
    "        if existing_hash not in seen_hashes:\n",
    "            cursor.execute(\"UPDATE jobs SET is_active = 0 WHERE hash = ?\", (existing_hash,))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_db()\n",
    "print(\"✅ Database initialized at:\", DB_NAME)\n",
    "#store_jobs(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_job_changes(current_jobs: List[Dict]) -> Dict[str, List[Dict]]:\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    now = datetime.utcnow().isoformat()\n",
    "\n",
    "    # Track what's seen this round\n",
    "    seen_urls = set()\n",
    "    new_jobs = []\n",
    "    changed_jobs = []\n",
    "\n",
    "    for job in current_jobs:\n",
    "        job_hash = generate_job_hash(job)\n",
    "        url = job['url']\n",
    "        seen_urls.add(url)\n",
    "\n",
    "        cursor.execute(\"SELECT hash FROM jobs WHERE url = ?\", (url,))\n",
    "        row = cursor.fetchone()\n",
    "\n",
    "        if row:\n",
    "            db_hash = row[0]\n",
    "            if db_hash != job_hash:\n",
    "                # Content changed → update hash and mark as changed\n",
    "                job[\"status\"] = \"changed\"\n",
    "                changed_jobs.append(job)\n",
    "                cursor.execute(\"\"\"\n",
    "                    UPDATE jobs\n",
    "                    SET hash = ?, title = ?, description = ?, last_seen = ?, is_active = 1\n",
    "                    WHERE url = ?\n",
    "                \"\"\", (job_hash, job['title'], job['description'], now, url))\n",
    "            else:\n",
    "                # Just update last_seen\n",
    "                cursor.execute(\"\"\"\n",
    "                    UPDATE jobs SET last_seen = ?, is_active = 1 WHERE url = ?\n",
    "                \"\"\", (now, url))\n",
    "        else:\n",
    "            # New job\n",
    "            job[\"status\"] = \"new\"\n",
    "            new_jobs.append(job)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO jobs (\n",
    "                    hash, title, url, description,\n",
    "                    company, source,\n",
    "                    first_seen, last_seen, is_active\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, 1)\n",
    "            \"\"\", (\n",
    "                job_hash,\n",
    "                job['title'],\n",
    "                url,\n",
    "                job['description'],\n",
    "                job.get('company', 'Unknown'),\n",
    "                job.get('source', 'Unknown'),\n",
    "                now,\n",
    "                now\n",
    "            ))\n",
    "\n",
    "    # Detect removed jobs (active jobs not in current scrape)\n",
    "    cursor.execute(\"SELECT url FROM jobs WHERE is_active = 1\")\n",
    "    all_active = {row[0] for row in cursor.fetchall()}\n",
    "\n",
    "    removed_urls = all_active - seen_urls\n",
    "    removed_jobs = []\n",
    "\n",
    "    for url in removed_urls:\n",
    "        removed_jobs.append({\"url\": url, \"status\": \"removed\"})\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE jobs SET is_active = 0 WHERE url = ?\n",
    "        \"\"\", (url,))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    return {\n",
    "        \"new\": new_jobs,\n",
    "        \"changed\": changed_jobs,\n",
    "        \"removed\": removed_jobs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = detect_job_changes(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
